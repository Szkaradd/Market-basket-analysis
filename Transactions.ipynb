{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87963d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa20cb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of column transaction_id is object\n",
      "Type of column sales_datetime is object\n",
      "Type of column customer_id is object\n",
      "Type of column product_id is object\n",
      "Type of column quantity is float64\n",
      "Type of column price is float64\n",
      "Type of column category_id is int64\n",
      "Type of column parent_id is int64\n",
      "Type of column store_id is int64\n",
      "Type of column department_id is int64\n",
      "Type of column salesperson_id is int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('edzd_trans_data.csv')\n",
    "# print type of each column\n",
    "for col in df.columns:\n",
    "    print(\"Type of column\", col, \"is\", df[col].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f000b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the type of product_id to int and number them from 1 to number of different product_ids\n",
    "df['product_id'] = df['product_id'].astype('category')\n",
    "df['product_id'] = df['product_id'].cat.codes\n",
    "\n",
    "# change the type of transaction_id to int and number them from 1 to number of different transaction_ids\n",
    "df['transaction_id'] = df['transaction_id'].astype('category')\n",
    "df['transaction_id'] = df['transaction_id'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8d95c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   transaction_id       sales_datetime customer_id  product_id  quantity  \\\n",
      "0          680577  2011-01-01 09:04:00          -1         157       1.0   \n",
      "1         3148654  2011-01-01 09:04:00          -1       43930       1.0   \n",
      "2         3148654  2011-01-01 09:04:00          -1       12666       1.0   \n",
      "3          651357  2011-01-01 09:08:00          -1       39576       1.0   \n",
      "4          651357  2011-01-01 09:08:00          -1       44343       1.0   \n",
      "\n",
      "   price  category_id  parent_id  store_id  department_id  salesperson_id  \n",
      "0   13.5          208         29        18              2             108  \n",
      "1    6.5          179         30        17              2             108  \n",
      "2    6.5          179         30        17              2             108  \n",
      "3   10.5          175         29         1              2             108  \n",
      "4   17.5          208         29         1              2             108  \n",
      "(8159536, 11)\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f6293c",
   "metadata": {},
   "source": [
    "## next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68dc9ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
      "0      0      0      0      0      0      0      0      0      0      0  ...   \n",
      "1      0      0      0      0      0      0      0      0      0      0  ...   \n",
      "2      0      0      0      0      0      0      0      0      0      0  ...   \n",
      "3      0      0      0      0      0      0      0      0      0      0  ...   \n",
      "4      0      0      0      0      0      0      0      0      0      0  ...   \n",
      "\n",
      "   94092  94093  94094  94095  94096  94097  94098  94099  94100  94101  \n",
      "0      0      0      0      0      0      0      0      0      0      0  \n",
      "1      0      0      0      0      0      0      0      0      0      0  \n",
      "2      0      0      0      0      0      0      0      0      0      0  \n",
      "3      0      0      0      0      0      0      0      0      0      0  \n",
      "4      0      0      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[5 rows x 94102 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a sparse matrix of the data group it by transaction_id and product_id\n",
    "my_basket = csr_matrix(\n",
    "    (df['quantity'], (df['transaction_id'], df['product_id'])))\n",
    "\n",
    "# change all positive values to 1 and all negative values to 0\n",
    "my_basket.data = np.where(my_basket.data > 0, 1, 0)\n",
    "\n",
    "# Create a dataframe of the sparse matrix\n",
    "my_basket = pd.DataFrame.sparse.from_spmatrix(my_basket)\n",
    "print(my_basket.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d277c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5090/1440229732.py:6: FutureWarning: The behavior of .astype from SparseDtype to a non-sparse dtype is deprecated. In a future version, this will return a non-sparse array with the requested dtype. To retain the old behavior, use `obj.astype(SparseDtype(dtype))`\n",
      "  my_basket_sets = my_basket_sets.astype(bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
      "0  False  False  False  False  False  False  False  False  False  False  ...   \n",
      "1  False  False  False  False  False  False  False  False  False  False  ...   \n",
      "2  False  False  False  False  False  False  False  False  False  False  ...   \n",
      "3  False  False  False  False  False  False  False  False  False  False  ...   \n",
      "4  False  False  False  False  False  False  False  False  False  False  ...   \n",
      "\n",
      "   94092  94093  94094  94095  94096  94097  94098  94099  94100  94101  \n",
      "0  False  False  False  False  False  False  False  False  False  False  \n",
      "1  False  False  False  False  False  False  False  False  False  False  \n",
      "2  False  False  False  False  False  False  False  False  False  False  \n",
      "3  False  False  False  False  False  False  False  False  False  False  \n",
      "4  False  False  False  False  False  False  False  False  False  False  \n",
      "\n",
      "[5 rows x 94102 columns]\n"
     ]
    }
   ],
   "source": [
    "my_basket_sets = my_basket\n",
    "\n",
    "# print(my_basket_sets.head())\n",
    "\n",
    "# change all values to boolean\n",
    "my_basket_sets = my_basket_sets.astype(bool)\n",
    "\n",
    "print(my_basket_sets.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0b606f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1369\n"
     ]
    }
   ],
   "source": [
    "# get date from string\n",
    "def get_date(string):\n",
    "    return datetime.strptime(string, '%Y-%m-%d %H:%M:%S').date()\n",
    "\n",
    "# number of days over which data was collected\n",
    "delta = get_date(max(df['sales_datetime'])) - get_date(min(df['sales_datetime']))\n",
    "days_count = delta.days\n",
    "print(days_count)\n",
    "\n",
    "# number of transactions in our data\n",
    "transactions_count = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b700b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 37 frequent itemsets\n"
     ]
    }
   ],
   "source": [
    "# frequent = appears at least in 20 transactions in a day\n",
    "min_support = 20 * days_count / transactions_count\n",
    "\n",
    "my_frequent_itemsets = apriori(my_basket_sets, min_support=min_support)\n",
    "\n",
    "print(\"there are \" + str(my_frequent_itemsets.shape[0]) + \" frequent itemsets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecaca036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 893 frequent itemsets\n"
     ]
    }
   ],
   "source": [
    "# frequent = appears at least in 3 transactions in a day\n",
    "min_support = 3 * days_count / transactions_count\n",
    "\n",
    "my_frequent_itemsets = fpgrowth(my_basket_sets, min_support=min_support)\n",
    "\n",
    "print(\"there are \" + str(my_frequent_itemsets.shape[0]) + \" frequent itemsets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5d3d40",
   "metadata": {},
   "source": [
    "## different way of getting the sparse matrix - by using TransactionEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8dc612d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1471, 42219, 13191, 15774, 48230, 91326, 84341], [87313, 1352, 55561, 56208, 30757, 11143], [59733], [51302, 41787, 69481, 44343], [64116]]\n"
     ]
    }
   ],
   "source": [
    "df_grouped = df.groupby('transaction_id')['product_id'].apply(list)\n",
    "dataset = df_grouped.tolist()\n",
    "print(dataset[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d07233",
   "metadata": {},
   "outputs": [],
   "source": [
    "te = TransactionEncoder()\n",
    "fitted = te.fit(dataset)\n",
    "te_ary = fitted.transform(dataset, sparse=True)\n",
    "my_basket = pd.DataFrame.sparse.from_spmatrix(te_ary, columns=te.columns_)\n",
    "print(my_basket.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38af1165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequent = appears at least in 30 transactions in a day\n",
    "min_support = 30 * days_count / transactions_count\n",
    "\n",
    "my_frequent_itemsets = apriori(my_basket, min_support=min_support)\n",
    "\n",
    "print(\"there are \" + str(my_frequent_itemsets.shape[0]) + \" frequent itemsets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc63ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequent = appears at least in 3 transactions in a day\n",
    "min_support = 3 * days_count / transactions_count\n",
    "\n",
    "my_frequent_itemsets = fpgrowth(my_basket, min_support=min_support)\n",
    "\n",
    "print(\"there are \" + str(my_frequent_itemsets.shape[0]) + \" frequent itemsets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae47399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_frequent_itemsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1dc765",
   "metadata": {},
   "source": [
    "## association rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43713a98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 10 association rules\n",
      "      antecedents     consequents  antecedent support  consequent support  \\\n",
      "0         (43990)         (76545)            0.000951            0.001194   \n",
      "1         (59576)         (76545)            0.000756            0.001194   \n",
      "2         (59576)         (43990)            0.000756            0.000951   \n",
      "3  (59576, 76545)         (43990)            0.000671            0.000951   \n",
      "4  (59576, 43990)         (76545)            0.000625            0.001194   \n",
      "5  (76545, 43990)         (59576)            0.000724            0.000756   \n",
      "6         (59576)  (76545, 43990)            0.000756            0.000724   \n",
      "7         (51138)         (28707)            0.000621            0.005530   \n",
      "8         (69718)         (28707)            0.000648            0.005530   \n",
      "9         (38102)         (11113)            0.000593            0.003726   \n",
      "\n",
      "    support  confidence         lift  leverage  conviction  \n",
      "0  0.000724    0.760779   636.920354  0.000722    4.175239  \n",
      "1  0.000671    0.886984   742.578603  0.000670    8.837728  \n",
      "2  0.000625    0.826452   868.966874  0.000624    5.756617  \n",
      "3  0.000593    0.883629   929.085338  0.000592    8.585048  \n",
      "4  0.000593    0.948349   793.953042  0.000592   19.337530  \n",
      "5  0.000593    0.819013  1083.210621  0.000592    5.521075  \n",
      "6  0.000593    0.783765  1083.210621  0.000592    4.621249  \n",
      "7  0.000621    1.000000   180.823574  0.000618         inf  \n",
      "8  0.000648    1.000000   180.823574  0.000645         inf  \n",
      "9  0.000593    1.000000   268.404175  0.000591         inf  \n"
     ]
    }
   ],
   "source": [
    "#only confidence\n",
    "\n",
    "my_association_rules = association_rules(my_frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n",
    "\n",
    "print(\"there are \" + str(my_association_rules.shape[0]) + \" association rules\")\n",
    "print(my_association_rules)\n",
    "# 10 rules for 893 frequent itemsets\n",
    "# 0 for 37 :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4ce384f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 100 association rules\n",
      "   antecedents consequents  antecedent support  consequent support   support  \\\n",
      "0      (87313)     (67214)            0.011430            0.005244  0.000528   \n",
      "1      (67214)     (87313)            0.005244            0.011430  0.000528   \n",
      "2      (61987)     (28829)            0.004918            0.013549  0.000944   \n",
      "3      (28829)     (61987)            0.013549            0.004918  0.000944   \n",
      "4       (6427)     (28829)            0.003664            0.013549  0.000971   \n",
      "..         ...         ...                 ...                 ...       ...   \n",
      "95     (14021)     (71292)            0.001490            0.001545  0.000527   \n",
      "96     (43946)      (6014)            0.001978            0.001167  0.000533   \n",
      "97      (6014)     (43946)            0.001167            0.001978  0.000533   \n",
      "98     (11113)     (38102)            0.003726            0.000593  0.000593   \n",
      "99     (38102)     (11113)            0.000593            0.003726  0.000593   \n",
      "\n",
      "    confidence        lift  leverage  conviction  \n",
      "0     0.046174    8.804687  0.000468    1.042911  \n",
      "1     0.100641    8.804687  0.000468    1.099193  \n",
      "2     0.191898   14.162804  0.000877    1.220701  \n",
      "3     0.069646   14.162804  0.000877    1.069574  \n",
      "4     0.265001   19.558090  0.000921    1.342112  \n",
      "..         ...         ...       ...         ...  \n",
      "95    0.353516  228.812746  0.000524    1.544438  \n",
      "96    0.269699  231.166655  0.000531    1.367701  \n",
      "97    0.457143  231.166655  0.000531    1.838462  \n",
      "98    0.159199  268.404175  0.000591    1.188637  \n",
      "99    1.000000  268.404175  0.000591         inf  \n",
      "\n",
      "[100 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#only lift\n",
    "\n",
    "my_association_rules = association_rules(my_frequent_itemsets, metric=\"lift\", min_threshold=1.2)\n",
    "\n",
    "print(\"there are \" + str(my_association_rules.shape[0]) + \" association rules\")\n",
    "print(my_association_rules)\n",
    "# 100 rules for 893 frequent itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c4024c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       antecedents consequents  antecedent support  consequent support  \\\n",
      "30  (59576, 76545)     (43990)            0.000671            0.000951   \n",
      "31  (59576, 43990)     (76545)            0.000625            0.001194   \n",
      "32  (76545, 43990)     (59576)            0.000724            0.000756   \n",
      "\n",
      "     support  confidence         lift  leverage  conviction  antecedent_len  \n",
      "30  0.000593    0.883629   929.085338  0.000592    8.585048               2  \n",
      "31  0.000593    0.948349   793.953042  0.000592   19.337530               2  \n",
      "32  0.000593    0.819013  1083.210621  0.000592    5.521075               2  \n"
     ]
    }
   ],
   "source": [
    "# antecedent_len >= 2, lift & confidence\n",
    " \n",
    "my_association_rules[\"antecedent_len\"] = my_association_rules[\"antecedents\"].apply(lambda x: len(x))\n",
    "\n",
    "my_association_rules = my_association_rules[ (my_association_rules['antecedent_len'] >= 2) &\n",
    "                                             (my_association_rules['confidence'] > 0.75) &\n",
    "                                             (my_association_rules['lift'] > 1.2) ]\n",
    "\n",
    "print(my_association_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c1e4f46",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       antecedents     consequents  antecedent support  consequent support  \\\n",
      "25         (43990)         (76545)            0.000951            0.001194   \n",
      "26         (59576)         (76545)            0.000756            0.001194   \n",
      "28         (59576)         (43990)            0.000756            0.000951   \n",
      "30  (59576, 76545)         (43990)            0.000671            0.000951   \n",
      "31  (59576, 43990)         (76545)            0.000625            0.001194   \n",
      "32  (76545, 43990)         (59576)            0.000724            0.000756   \n",
      "33         (59576)  (76545, 43990)            0.000756            0.000724   \n",
      "60         (51138)         (28707)            0.000621            0.005530   \n",
      "81         (69718)         (28707)            0.000648            0.005530   \n",
      "99         (38102)         (11113)            0.000593            0.003726   \n",
      "\n",
      "     support  confidence         lift  leverage  conviction  antecedent_len  \n",
      "25  0.000724    0.760779   636.920354  0.000722    4.175239               1  \n",
      "26  0.000671    0.886984   742.578603  0.000670    8.837728               1  \n",
      "28  0.000625    0.826452   868.966874  0.000624    5.756617               1  \n",
      "30  0.000593    0.883629   929.085338  0.000592    8.585048               2  \n",
      "31  0.000593    0.948349   793.953042  0.000592   19.337530               2  \n",
      "32  0.000593    0.819013  1083.210621  0.000592    5.521075               2  \n",
      "33  0.000593    0.783765  1083.210621  0.000592    4.621249               1  \n",
      "60  0.000621    1.000000   180.823574  0.000618         inf               1  \n",
      "81  0.000648    1.000000   180.823574  0.000645         inf               1  \n",
      "99  0.000593    1.000000   268.404175  0.000591         inf               1  \n"
     ]
    }
   ],
   "source": [
    "my_association_rules[\"antecedent_len\"] = my_association_rules[\"antecedents\"].apply(lambda x: len(x))\n",
    "\n",
    "my_association_rules = my_association_rules[ (my_association_rules['antecedent_len'] >= 1) &\n",
    "                                             (my_association_rules['confidence'] > 0.75) &\n",
    "                                             (my_association_rules['lift'] > 1.2) ]\n",
    "\n",
    "print(my_association_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401f3029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jakie warto dać wykresuchy?\n",
    "\n",
    "# ile dostajemy frequent item sets w zależności od min support?\n",
    "# to byłby taki wykres + dyskusja o tym jaki support ma sens względem rozmiaru danych i okresu czasu, z którego są dane\n",
    "\n",
    "# ile dostajemy association rules w zależności od confidence, support, lift? (3 wykresy wow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c362195",
   "metadata": {},
   "outputs": [],
   "source": [
    "#support a rozmiar danych i okres czasu, z którego są dane\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c109b600",
   "metadata": {},
   "source": [
    "# Customer analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08f95a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
